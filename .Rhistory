species <- read.table("../../Result/03.profile/Species/Berber.update.species.pro", row.names = 1, header = 1, sep = "\t")
species.clean <- species[, rownames(phe)]
bileacid <- read.csv("../../Result/17.metabolism/Bileacid.metabolism.v2.csv", header = T, row.names = 1)
bileacid.clean <- bileacid[rownames(phe), ]
# clean data
filter.species <- read.table("../../Result/03.profile/Species/Berber.species.gene.num.perSample.txt", header = T, row.names = 1, sep = "\t")
retain <- names(which(apply(filter.species, 1, function(x){sum(x>=100)/length(x)})>=0.2))
retain <- gsub(" ", "_", retain)
species.clean2 <- species.clean[retain, ]
# 9 species  # tmp add R for figure
species.list2 <- c("Bifidobacterium_breve",
"Bifidobacterium_longum",
"Lactobacillus_casei",
"Lactobacillus_crispatus",
"Lactobacillus_fermentum",
"Lactobacillus_plantarum",
"Lactobacillus_rhamnosus",
"Lactobacillus_salivarius",
"Lactobacillus_gasseri",
"Ruminococcus_bromii"
)
species.pro <- species.clean[species.list2, ]
# filter bileacid
#bileacid.list <- read.table("../09.spearman/bileacid.list.txt")
#bileacid.clean2 <- bileacid.clean[, as.character(bileacid.list$V1)]
bileacid.clean2 <- bileacid.clean
# retain the phenotyep
phe.list <- read.table("../09.spearman/phe.list.txt")
phe.clean2 <- phe[, c(as.character(phe.list[,1]), "PatientID", "Group", "Time")]
# to confirm the dat is OK
if(any(rownames(bileacid.clean2)==rownames(phe)) & any(rownames(phe)==colnames(species.clean))){
print("data is OK")
}else{
stop("check the sample ID")
}
trans <- function(x){
if(length(x[x==0])!=0){
min.value <- min(x[x!=0])/2
x[x==0] <- min.value
x <- log(x)
}else{
x <- log(x)
}
return(x)
}
# trans pvalue
# bileacid
# gee
mygee<- function(bile, phe_clean, spe, group, confound){
# ready the dat
if(!is.na(pmatch(group, c(1:4)))){
phe_clean_g1 <- phe_clean[phe_clean$Group == group, ]
}else{
phe_clean_g1 <- phe_clean[phe_clean$Group == 1| phe_clean$Group == 3, ]
}
base <- phe_clean_g1[phe_clean_g1$Time==1, ]
end <- phe_clean_g1[phe_clean_g1$Time==3, ]
id <- intersect(base$PatientID, end$PatientID)
base2 <- base[pmatch(id, base$PatientID), ]
end2 <- end[pmatch(id, end$PatientID), ]
end2$BMI <- base2$BMI
confounder <- rbind(base2[,c("age", "sex", "BMI", "PatientID")], end2[,c("age", "sex", "BMI", "PatientID")])
base_bc <- bile[rownames(base2), ]
end_bc <- bile[rownames(end2), ]
base_sp <- t(spe[,rownames(base2)])
end_sp <- t(spe[,rownames(end2)])
if(any(rownames(base_bc) == rownames(base_sp)) & any(rownames(base_bc) == rownames(base2))){
print("sample is OK")
}else{
stop("Check the sample id!")
}
result <- matrix(NA, nrow = ncol(base_sp), ncol = ncol(base_bc)*2)
result <- as.data.frame(result)
for(i in 1:ncol(base_sp)){
rownames(result)[i] <- colnames(base_sp)[i]
print(i)
for(j in 1:ncol(base_bc)){
dat_com <- data.frame(bc = c(base_bc[,j], end_bc[,j]),
sp = c(base_sp[,i], end_sp[,i]),
confounder)
#confirm the data type
dat_com$sex <- as.factor(dat_com$sex)
dat_com$sp  <- trans(dat_com$sp)
if(confound == "T"){
# rm the gee
formula2 <- formula(bc~sp+BMI+sex+age)
}else{
formula2 <- formula(bc~sp)
}
dat_com <- dat_com[!is.na(dat_com$bc), ]
dat_com$bc <- scale(dat_com$bc)
dat_com$sp <- scale(dat_com$sp)
geeInd <- geem(formula2, id=PatientID, data=dat_com, family=gaussian, corstr="unstr")
tmp <- summary(geeInd)
result[i, c((2*j-1):(2*j))] <- c(tmp$beta[2], tmp$p[2])
colnames(result)[c((2*j-1):(2*j))] <- paste0(colnames(base_bc)[j], c("_estimate", "_p.value"))
}
}
return(result)
}
# phenotype & bileacid
mygee2 <- function(bile , phe_clean,  group){
# ready the data
if(!is.na(pmatch(group, c(1:4)))){
phe_clean_g1 <- phe_clean[phe_clean$Group == group, ]
}else{
phe_clean_g1 <- phe_clean[phe_clean$Group == 1 | phe_clean$Group == 3, ]
}
base <- phe_clean_g1[phe_clean_g1$Time==1, ]
end <- phe_clean_g1[phe_clean_g1$Time==3, ]
id <- intersect(base$PatientID, end$PatientID)
base2 <- base[pmatch(id, base$PatientID), ]
end2 <- end[pmatch(id, end$PatientID), ]
confounder <- rbind(base2[,c("age", "sex", "BMI", "PatientID")], end2[,c("age", "sex", "BMI", "PatientID")])
base_bc <- bile[rownames(base2), ]
end_bc  <- bile[rownames(end2), ]
if(any(rownames(base_bc) == rownames(base2))){
print("sample is OK")
}else{
stop("Check the sample id!")
}
result <- matrix(NA, nrow = ncol(base2)-3, ncol = ncol(base_bc)*2)
result <- as.data.frame(result)
for(i in 1:c(ncol(base2)-3)){
rownames(result)[i]<- phe_name <- colnames(base2)[i]
print(i)
for(j in 1:ncol(base_bc)){
dat_com <- data.frame(bc = c(base_bc[,j], end_bc[,j]),
ph = c(base2[,i], end2[,i]),confounder)
#confirm the data type
dat_com$sex <- as.factor(dat_com$sex)
#dat_com$sp  <- trans(dat_com$sp)
# age, sex, bmi
if(phe_name=="sex"){
formula2 <- formula(bc~ph+BMI+age)
}else if(phe_name=="age"){
formula2 <- formula(bc~ph+BMI+sex)
}else if(phe_name=="BMI"){
formula2 <- formula(bc~ph+age+sex)
}else if(phe_name=="height" | phe_name=="weight"){
formula2 <- formula(bc~ph+age+sex)
}else{
formula2 <- formula(bc~ph+BMI+age+sex)
}
dat_com <- dat_com[!is.na(dat_com$bc) & !is.na(dat_com$ph), ]
dat_com$bc <- scale(dat_com$bc)
dat_com$ph <- scale(dat_com$ph)
geeInd <- geem(formula2, id=PatientID, data=dat_com, family=gaussian, corstr="unstructured")
tmp <- summary(geeInd)
result[i, c((2*j-1):(2*j))] <- c(tmp$beta[2], tmp$p[2])
colnames(result)[c((2*j-1):(2*j))] <- paste0(colnames(base_bc)[j], c("_estimate", "_p.value"))
}
}
return(result)
}
# figure
trans2 <- function(x){
#x <- p.adjust(x, method = "BH")
if(x <= 0.05 & x>0.01){
out <-"*"
}else if(x <= 0.01 & x>0.001){
out <- "**"
}else if(x <= 0.001){
out<- "***"
}else{
out <- " "
}
return(out)
}
figure <- function(x){
xname <- rownames(x)
x <- apply(x, 2, as.numeric)
sp.corr.t <- x
rownames(sp.corr.t) <- xname
index <- 2*c(1:(ncol(sp.corr.t)/2))
dat.pvalue <- sp.corr.t[,index]
dat.pvalue2 <- matrix(p.adjust(dat.pvalue, method = "BH"), nrow = nrow(dat.pvalue))
dat.cor <- sp.corr.t[,-index]
colnames(dat.cor) <- colnames(dat.pvalue)
#pvalue.index <- apply(dat.pvalue, 2, function(x) any(x < 0.01))
#pvalue.index2 <- apply(dat.pvalue, 1, function(x) any(x < 0.01))
#dat.cor.cle <- dat.cor[pvalue.index2, pvalue.index]
dat.cor.cle <- dat.cor
colnames(dat.cor.cle) <- gsub("_p.value", "", colnames(dat.cor.cle))
#dat.pva.cle <- dat.pvalue[pvalue.index2, pvalue.index]
dat.pva.cle <- dat.pvalue2
num<- matrix(NA,nrow = nrow(dat.pva.cle), ncol = ncol(dat.pva.cle))
for(i in 1:ncol(dat.pva.cle)){
num[,i] <- mapply(trans2, dat.pva.cle[,i])
}
#colt<-c("#4C38CB","#9191C8","#DADAEC","#F0C1C1","#E28383","#D44545","#CD2626")
colt3<-c("#164a83","#2565a3","#79b3d5","#bdd6e6","#f3f9fc", "#fff6f1","#df896b","#d06651","#bd433e","#b31f2c")
pheatmap(t(dat.cor.cle),
treeheight_row=43,
treeheight_col=23,
cellwidth=20,
cellheight=8,
cluster_cols=T,
cluster_rows=T,
fontsize_row=8,
fontsize_col=13,
show_colnames=T,
display_numbers=t(num),
color =colt3,
#breaks=seq(-0.6,0.6,0.2),
#legend_breaks = c(-0.6,-0.3, 0, 0.3,0.6),
#legend_labels = c("-0.6","-0.3","0", "0.3", "0.6"),
number_color = "white")
}
dim(species.clean2)
library(rmeta)
library(rmeta)
pip.dat <- readxl::read_excel("../../result/00.data/bjt2d.REPORT.xlsx",col_names = T)
dat.reads.num <- pip.dat[,c("raw.reads","abun_size")]
raw.less20m <- sum(pip.dat$raw.reads<20000000)
abun.less20m <- sum(pip.dat$abun_size<20000000)
dat.reads.num2 <- reshape2::melt(dat.reads.num)
ggplot(dat.reads.num2,aes(value/1e6,color=variable))+
geom_line(stat = "density",size=0.8)+
geom_vline(xintercept = 20,size=1,linetype="dashed")+
scale_x_continuous(breaks = c(0,20,50,100,150))+
theme_classic()+
#mytheme+
xlab("reads number(M paired)")
dat.pip.qc <- pip.dat[,ncol(pip.dat)-c(5,3:0)]
dat.pip.qc2 <- dat.pip.qc[order(dat.pip.qc$mapped.reads),]
nm.order <- rownames(dat.pip.qc2)
dat.pip.qc2$sample <- rownames(dat.pip.qc2)
dat.pip.qc2 <- reshape2::melt(dat.pip.qc2,id.vars = c("coverage","sample"),
variable.name = "stage")
dat.pip.qc2$stage <- factor(dat.pip.qc2$stage,
levels = c("lowQ.reads","host.reads","unmapped.reads","mapped.reads"))
dat.pip.qc2$sample <- factor(dat.pip.qc2$sample,levels = nm.order)
dat.pip.qc2$value <- dat.pip.qc2$value/1e6
ggplot(dat.pip.qc2,aes(sample,value,fill=stage))+
geom_bar(stat = "identity")+
geom_hline(yintercept = 20)+
theme_classic()+
#mytheme+
theme(axis.text.x = element_blank(),
# legend.position = c(0.01,0.99),
#legend.justification = c(0,1),
axis.ticks = element_blank())+
xlab("")+ylab("reads number (M)")+
scale_y_continuous(expand = c(0,0),breaks = c(0,20,40,80,120,160))
library(dunn.test)
a <- c(1:6)
b <- c(7:12)
wilcox.test(a, b)
wilcox.test(a, b)$p.value
wilcox.test(a, b)$p.value*15
?p.adjust
sample(seq(0.001,0.01, 0.01))
sample(seq(0.001,0.01, 0.01), 10)
sample(seq(0.001,0.01, 0.001), 10)
sample(seq(0.001,0.01, 0.001), 10) -> pvalue
p.adjust(pvalue, method = "BH")
p.adjust(pvalue, method = "fdr")
install.packages("rsq")
library(rsq)
data(hcrabs)
attach(hcrabs)
y <- ifelse(num.satellites>0,1,0)
bnfit <- glm(y~color+spine+width+weight,family=binomial)
rsq(bnfit)
rsq(bnfit,adj=TRUE)
bnfit
data(hcrabs)
attach(hcrabs)
y <- ifelse(num.satellites>0,1,0)
bnfit <- glm(y~color+spine+width+weight,family=binomial)
rsq.partial(bnfit)
glm(color~spine+width+weight)
color
spine
width
a <- lm(width~spine+color+weight)
b <- lm(width~spine+weight)
summary(a)
str(summary(a))
summary(a)$adj.r.squared
summary(b)$adj.r.squared
b <- lm(width~spine+color)
summary(b)$adj.r.squared
c <- glm(width~spine+color+weight)
rsq.partial(c)
summary(b)$r.squared
summary(a)$r.squared
rsq.partial
?rsq.partial
lmmode
summary(lmmode)
lmmode$residuals
lmmode$df
lmmode
example(glm)
summary(anorex.1)
anorex.1$df.residual
lmmode
glm(formula = valiPhe ~ risk)
glm(formula = valiPhe ~ risk) -> a
a$df.residual
length(risk)
lmmode$df
lmmode$df[2]
lmmode$r.squared
library(rmeta)
library(rmeta)
c("a", "b", "c")
c("a", "b", "c") -> a
c(TRUE, FALSE, TRUE) -> b
b[a]
a[b]
ifelse(b,a,"")
?xlab
library(coin)
c("a", "b", "c")
paste0(rep(c("a", "b"),3), c("ratio", "mean", "median"))
paste0(rep(c("a", "b"),each=3), c("ratio", "mean", "median"))
comparePair <- function(data, config, group, ...){
# wilcox test on multigroup
nlevle <- levels(config[, group])
if(length(nlevle) >2 ){
combng <- combn(nlevle, 2)
out <- list()
for(i in 1:ncol(combng)){
subconfig <- config[config[,group] %in% combng[,i], ]
out[i] <- mywilcox_2t(data, subconfig, ...)
}
return(out)
}else{
res <- mywilcox_2t(data, config, ...)
return(out)
}
}
mywilcox_2t <- function(datamatrix, configdata, Time2, ratio="zero",...){
# to sort the data
config <- matchID(configdata, ...)
data <- datamatrix[rownames(config), ,drop=F]
# to analysis
out <- matrix(NA, nrow = ncol(data), ncol = 9)
config <- as.factor(config[, Time2])
nlevels = levels(config)
for(i in 1:ncol(data)){
tmp <- as.numeric(data[,i])
g1 <- tmp[config == nlevels[1]]
g2 <- tmp[config == nlevels[2]]
wilcox_sign <- pvalue(wilcoxsign_test(g1~g2))
effect <- wilcoxonPairedR(x <- tmp, g <- config)
if(ratio=="zero"){
or <- tapply(tmp, config, function(x){sum(x!=0, na.rm=T)/length(x)})
}else{
or <- tapply(tmp, config, function(x){sum(!is.na(x))/length(x)})
}
mean_abun <- tapply(tmp, config, mean, na.rm=T)
median_abun <-  tapply(tmp, config,  median, na.rm=T)
z_score <- statistic(wilcoxsign_test(g1~g2))
out[i, 1:9] <- c(wilcox_sign, or, mean_abun, median_abun, z_score, effect)
}
# out
rownames(out) <- colnames(data)
colnames(out) <- c("sign_p.value",paste0(rep(nlevels,3),
c("_ratio", "_mean", "_median")), "z_score", "effect_size")
out <- as.data.frame(out)
out$p.adjust <- p.adjust(out$sign_p.value, method = "BH")
out$enrich <- ifelse(out$p.adjust<0.05, ifelse(out$z_score>0,
nlevels[1], nlevels[2]), "none")
return(out)
}
??dudi.pco
?pam
??pam
rep(c("a","b"), 2)
paste0(rep(c("a","b"), 2), c("ratio", "mean"))
paste0(rep(c("a","b"), 2), rep(c("ratio", "mean"), 2))
paste0(rep(c("a","b"), 2), rep(c("ratio", "mean"), each =2))
mywilcox_2t <- function(datamatrix, configdata, Time2, ratio="zero",...){
# to sort the data
config <- matchID(configdata, ...)
data <- datamatrix[rownames(config), ,drop=F]
# to analysis
out <- matrix(NA, nrow = ncol(data), ncol = 9)
config <- as.factor(as.character(config[, Time2]))
nlevels = levels(droplevels(config))
for(i in 1:ncol(data)){
tmp <- as.numeric(data[,i])
g1 <- tmp[config == nlevels[1]]
g2 <- tmp[config == nlevels[2]]
wilcox_sign <- pvalue(wilcoxsign_test(g1~g2))
effect <- wilcoxonPairedR(x <- tmp, g <- config)
if(ratio=="zero"){
or <- tapply(tmp, config, function(x){sum(x!=0, na.rm=T)/length(x)})
}else{
or <- tapply(tmp, config, function(x){sum(!is.na(x))/length(x)})
}
mean_abun <- tapply(tmp, config, mean, na.rm=T)
median_abun <-  tapply(tmp, config,  median, na.rm=T)
z_score <- statistic(wilcoxsign_test(g1~g2))
out[i, 1:9] <- c(wilcox_sign, or, mean_abun, median_abun, z_score, effect)
}
# out
rownames(out) <- colnames(data)
colnames(out) <- c("sign_p.value",paste0(rep(nlevels,3),
rep(c("_ratio", "_mean", "_median"), each=2)),
"z_score", "effect_size")
out <- as.data.frame(out)
out$p.adjust <- p.adjust(out$sign_p.value, method = "BH")
out$enrich <- ifelse(out$p.adjust<0.05, ifelse(out$z_score>0,
nlevels[1], nlevels[2]), "none")
return(out)
}
library(caret)
?createFolds
createFolds(c(1:100), k = 10)
createFolds(c(2:100), k = 10)
createFolds(c(2:200), k = 10)
unlist(createFolds(c(2:200), k = 10))
as.vector(unlist(createFolds(c(2:200), k = 10)))
r2Twopartmodelcv <- function(dat , phe, response, cutoff, number=10, cutoffp=0.01, repeatN=100, fold,confounder=NULL){
# match the sample ID
id <- intersect(rownames(dat), rownames(phe))
if(length(id)==0){
stop("can't match the sample id")
}
dat <- dat[id, ]
phe <- phe[id, ]
R2 <- c()
for(m in 1:repeatN){
# print(m)
# cross vlidation
sampNum <- nrow(dat)
foldlist <- createFolds(1:sampNum, k = fold)
risk <- rep(NA, sampNum)
for(n in 1:fold){
discSampindex <- c(1:sampNum)[-foldlist[[n]]]
valiSampindex <- foldlist[[n]]
discDatax <- dat[discSampindex, ]
discPhe <- phe[discSampindex, ]
valiDatax <- dat[valiSampindex, ]
valiPhe <- phe[valiSampindex, response]
# twopart Model to get the effect size
twopartRes <- twopartModel(dat = discDatax, phe = discPhe, response = response,
cutoff = cutoff, number = number)
featurelist <- rownames(twopartRes)[twopartRes[,15] <= cutoffp]
if(length(featurelist)==0){
risk[foldlist[[n]]] <- 0  # if no feature, the rish set zero
next
print(paste0("pvalue cutoff :", cutoffp, " can't get any feature"))
}else{
print(paste0("pvalue cutoff :", cutoffp, " get the significant feature ",
length(featurelist)))
}
# get the additive modele
twopartRes2 <- twopartRes[featurelist, ,drop=F]
valiDatax2  <- valiDatax[, featurelist, drop=F]
risk <- c()
for(i in 1:nrow(valiDatax2)){
riskvalue <- c()
for(j in 1:ncol(valiDatax2)){
beta1 <- twopartRes2[, 4]
beta2 <- twopartRes2[, 8]
b <- ifelse(valiDatax2[i, j] <= cutoff, 0, 1)
q <- ifelse(valiDatax2[i, j] <= cutoff, 0, log10(valiDatax2[i,j]))
riskvalue[j] <- beta1+b+beta2*q  # can't not ecsure why add b
}
risk[foldlist[[n]][i]] <- sum(riskvalue)
}
}
# get the R square
foldindex <- as.vector(unlist(foldlist))
if(!is.null(confounder)){
# risk
tmp <- phe[foldindex, c(response, confounder)]
tmp$risk <- risk
formula <- as.formula(paste0(response, "~."))
lmmode <- summary(lm(formula, data = tmp))
# no risk
tmp2 <- tmp[,-ncol(tmp)]
formula2 <- as.formula(paste0(response, "~."))
lmmode2 <- summary(lm(formula2, data = tmp2))
#　from the rsq.partial in the rsq package
R2[m] <- 1-((1-lmmode$r.squared)/(1-lmmode2$r.squared))*(lmmode2$df[2]/lmmode$df[2])
#R2[m] <- lmmode$adj.r.squared-lmmode2$adj.r.squared
}else{
y <- phe[foldindex, response]
print(y)
print(risk)
lmmode <- summary(lm(y~risk))
R2[m] <- lmmode$r.squared
}
}
return(R2)
}
createFolds(c(1:100), k = 10) -> foldlist
foldlist[[1]]
foldlist[[2]]
foldlist[[3]]
?aes_string
library(ggplot)
install.packages("ggplot2")
a <- "f->f"
a
`a`
``a``
tmp <- data.frame("f->f"=c(1:3))
tmp
tmp <- data.frame("f:f"=c(1:3))
tmp
tmp <- data.frame("3f"=c(1:3))
tmp
install.packages("Rd2roxygen")
library(Rtools)
